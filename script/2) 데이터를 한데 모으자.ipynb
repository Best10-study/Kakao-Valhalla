{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "PREP_DIR = os.path.join(DATA_DIR, \"prep\")\n",
    "TRAIN_DIR = os.path.join(RAW_DIR,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "    우리의 카카오 데이터를 한 데 모읍시다. 80기가가 되는데, 어떻게 줄여야 할지 고민해보아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcateid   의 메모리 size :    3MB(0.03%)\n",
      "brand     의 메모리 size :  124MB(1.38%)\n",
      "dcateid   의 메모리 size :    3MB(0.03%)\n",
      "img_feat  의 메모리 size : 7812MB(87.04%)\n",
      "maker     의 메모리 size :  274MB(3.05%)\n",
      "mcateid   의 메모리 size :    3MB(0.03%)\n",
      "model     의 메모리 size :  142MB(1.58%)\n",
      "pid       의 메모리 size :   11MB(0.12%)\n",
      "price     의 메모리 size :    3MB(0.03%)\n",
      "product   의 메모리 size :  583MB(6.50%)\n",
      "scateid   의 메모리 size :    3MB(0.03%)\n",
      "updttm    의 메모리 size :   14MB(0.16%)\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(os.path.join(TRAIN_DIR,\"train.chunk.01\"),'r')\n",
    "\n",
    "# attribute 별 memory사이즈를 계산\n",
    "attr_size_dict = {}\n",
    "for key in f['train'].keys():\n",
    "    value = f['train'][key]\n",
    "    mb_size = (value.size * value.dtype.itemsize) // (1024**2)\n",
    "    attr_size_dict[key] = mb_size\n",
    "\n",
    "tot_size = sum(attr_size_dict.values())\n",
    "\n",
    "for key, value in attr_size_dict.items():\n",
    "    print(\"{:10}의 메모리 size : {:4}MB({:2.2f}%)\".format(\n",
    "        key,value,value/tot_size*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Feature가 차지하는 메모리 분량이 87%나 된다.\n",
    "즉 89기가 중 대략 77기가가 이미지 정보이고, 12기가 정도가 그 외 정보가 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 Feature를 제외하고 다른 Feature들은 하나의 h5 파일로 모아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:35<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 파일의 사이즈 : 9519mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "merge_dir = TRAIN_DIR\n",
    "# merge 하고자 하는 데이터 셋의 파일 path \n",
    "file_paths = [os.path.join(merge_dir,file_name)\n",
    "              for file_name in os.listdir(merge_dir)\n",
    "              if \"chunk\" in file_name]\n",
    "\n",
    "prep_path = os.path.join(PREP_DIR,\"train_string.h5\")\n",
    "write_file = h5py.File(prep_path,\"w\")\n",
    "\n",
    "attrs = list(f['train'].keys()) # Merge할 attribute의 list\n",
    "attrs.remove('img_feat') # img_feat 제거\n",
    "for attr in tqdm(attrs):\n",
    "    values = []\n",
    "    for file_path in file_paths:\n",
    "        with h5py.File(file_path,'r') as read_file:\n",
    "            value = read_file['train'][attr][:]\n",
    "        values.append(value)\n",
    "    merge_value = np.concatenate(values)\n",
    "    write_file.create_dataset(attr,data=merge_value)\n",
    "write_file.close()\n",
    "\n",
    "print(\"저장된 파일의 사이즈 : {}mb\".format(\n",
    "    os.stat(prep_path).st_size // (1024**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단일 파일로 이제 9기가 정도의 파일로 줄어들었다. 로컬 컴퓨터에서도 이제 데이터 탐색이 가능한 사이즈로 줄어들었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와 같은 짓거리를 Test데이터셋에서도 해야 하고, dev데이터셋에서도 해야한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "직접 위의 코드를 돌리고 싶으면\n",
    "bash 창에서, \n",
    "\n",
    "```shell\n",
    "python data_utils.py preprocess ./data/raw/train/ ./data/prep/train_string.h5\n",
    "python data_utils.py preprocess ./data/raw/test/ ./data/prep/test_string.h5\n",
    "python data_utils.py preprocess ./data/raw/dev/ ./data/prep/dev_string.h5\n",
    "```\n",
    "\n",
    "을 하면 각각 train, test, dev 데이터셋이 생긴다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
